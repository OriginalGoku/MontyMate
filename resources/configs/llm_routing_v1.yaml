# resources/configs/llm_routing_v2.yaml
llm_routing:
  version: 2

  # The runner should:
  # 1) select role.primary if it satisfies decision_record.model_policy
  # 2) else try role.fallbacks in order
  # 3) fail with a clear reason if no candidate satisfies policy
  selection:
    strategy: primary_then_fallback
    enforce_model_policy: true
    # If true, runner should record the resolved model choice in provenance_manifest.
    record_resolution_in_provenance: true

  # Catalog is the source of truth for tags used by decision_record.model_policy.
  # Tags are intentionally simple and stable: cheap|standard|high.
  model_catalog:
    - id: openai:gpt-4.1-mini
      provider: openai
      model: gpt-4.1-mini
      tags:
        quality: standard
        cost: cheap
        latency: fast
      notes:
        - "Good for fast structured checks and tool calling; large context per OpenAI docs."

    - id: openai:gpt-4.1
      provider: openai
      model: gpt-4.1
      tags:
        quality: high
        cost: standard
        latency: medium
      notes:
        - "Stronger general model; use for architecture/review when needed."

    - id: openai:gpt-5-mini
      provider: openai
      model: gpt-5-mini
      tags:
        quality: high
        cost: standard
        latency: medium
      notes:
        - "Recommended by OpenAI as a strong default for more complex tasks."

    - id: openai:gpt-5
      provider: openai
      model: gpt-5
      tags:
        quality: high
        cost: high
        latency: slow
      notes:
        - "Use sparingly for hard reviews or long-horizon reasoning."

    - id: anthropic:claude-3.5-sonnet
      provider: anthropic
      model: claude-3.5-sonnet
      tags:
        quality: high
        cost: standard
        latency: medium
      notes:
        - "Anthropic Sonnet line; strong writing and reasoning per Anthropic materials."

    # Optional (only if you use it / have access). Keep it disabled by default.
    - id: anthropic:claude-3.7-sonnet
      provider: anthropic
      model: claude-3.7-sonnet
      tags:
        quality: high
        cost: standard
        latency: medium
      availability:
        enabled: false
      notes:
        - "Optional newer Sonnet family; enable when your provider account supports it."

  # Role routing: choose defaults that work well with your spec-first approach.
  # The policy layer (decision_record.model_policy) can still constrain allowed tags by risk.
  roles:
    interviewer:
      primary: openai:gpt-4.1-mini
      fallbacks:
        - openai:gpt-5-mini
        - anthropic:claude-3.5-sonnet

    # NEW role for MontyMate v2 workflow
    spec_validator:
      primary: openai:gpt-4.1-mini
      fallbacks:
        - openai:gpt-4.1
        - openai:gpt-5-mini

    researcher:
      primary: openai:gpt-5-mini
      fallbacks:
        - anthropic:claude-3.5-sonnet
        - openai:gpt-4.1

    architect:
      primary: openai:gpt-4.1
      fallbacks:
        - openai:gpt-5-mini
        - anthropic:claude-3.5-sonnet

    reviewer:
      primary: openai:gpt-4.1
      fallbacks:
        - openai:gpt-5
        - anthropic:claude-3.5-sonnet

    builder:
      primary: openai:gpt-4.1
      fallbacks:
        - openai:gpt-5-mini
        - anthropic:claude-3.5-sonnet

    qa:
      primary: openai:gpt-4.1-mini
      fallbacks:
        - openai:gpt-4.1
        - openai:gpt-5-mini

  # Optional: pricing references for your cost tables.
  # (You said youâ€™ll compute at call time using pricing tables in SQLite; these URLs are just human references.)
  pricing_references:
    openai_api_pricing_page: "https://openai.com/api/pricing/"
    openai_platform_pricing_doc: "https://platform.openai.com/docs/pricing"
    notes:
      - "OpenAI tool pricing (e.g., web search / code interpreter) is documented in platform pricing."
